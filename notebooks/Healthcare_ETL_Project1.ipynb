{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd59838",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee76a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T00:01:01.957297Z",
     "iopub.status.busy": "2025-04-25T00:01:01.956925Z",
     "iopub.status.idle": "2025-04-25T00:01:03.070483Z",
     "shell.execute_reply": "2025-04-25T00:01:03.069898Z"
    },
    "papermill": {
     "duration": 1.132734,
     "end_time": "2025-04-25T00:01:03.071679",
     "exception": false,
     "start_time": "2025-04-25T00:01:01.938945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af2a596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T00:01:03.079743Z",
     "iopub.status.busy": "2025-04-25T00:01:03.079541Z",
     "iopub.status.idle": "2025-04-25T00:01:03.776852Z",
     "shell.execute_reply": "2025-04-25T00:01:03.776487Z"
    },
    "papermill": {
     "duration": 0.701389,
     "end_time": "2025-04-25T00:01:03.777946",
     "exception": false,
     "start_time": "2025-04-25T00:01:03.076557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "import sqlite3\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8db6c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04aca0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T00:01:03.783397Z",
     "iopub.status.busy": "2025-04-25T00:01:03.783217Z",
     "iopub.status.idle": "2025-04-25T00:01:04.077092Z",
     "shell.execute_reply": "2025-04-25T00:01:04.076436Z"
    },
    "papermill": {
     "duration": 0.297418,
     "end_time": "2025-04-25T00:01:04.077965",
     "exception": true,
     "start_time": "2025-04-25T00:01:03.780547",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/avinashmacbookair/Documents/TREND Health Partners/Dataset/Healthcare_Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/avinashmacbookair/Documents/TREND Health Partners/Dataset/Healthcare_Dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/avinashmacbookair/Documents/TREND Health Partners/Dataset/Healthcare_Dataset.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/avinashmacbookair/Documents/TREND Health Partners/Dataset/Healthcare_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13bc1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "df['treatment_start_date'] = pd.to_datetime(df['treatment_start_date'])\n",
    "df['treatment_completion_date'] = pd.to_datetime(df['treatment_completion_date'])\n",
    "\n",
    "# Extract date and time parts\n",
    "df['treatment_start_date_only'] = df['treatment_start_date'].dt.date\n",
    "df['treatment_start_time_only'] = df['treatment_start_date'].dt.time\n",
    "df['treatment_end_date_only'] = df['treatment_completion_date'].dt.date\n",
    "df['treatment_end_time_only'] = df['treatment_completion_date'].dt.time\n",
    "\n",
    "# Drop original datetime columns\n",
    "df.drop(columns=['treatment_start_date', 'treatment_completion_date'], inplace=True)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e29c31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a1b62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to datetime once and store in a temp variable\n",
    "outcome_datetime = pd.to_datetime(df['treatment_outcome_date'])\n",
    "\n",
    "# Split into new date and time columns\n",
    "df['treatment_outcome_date'] = outcome_datetime.dt.date\n",
    "df['treatment_outcome_time'] = outcome_datetime.dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7fdf2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37bd93b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'treatment_start_date_only': 'treatment_start_date', 'treatment_start_time_only': 'treatment_start_time','treatment_end_date_only':'treatment_end_date','treatment_end_time_only':'treatment_end_time'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0334df6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to datetime to ensure correct operations\n",
    "df['treatment_outcome_date'] = pd.to_datetime(df['treatment_outcome_date'])\n",
    "df['treatment_end_date'] = pd.to_datetime(df['treatment_end_date'])\n",
    "\n",
    "# Add Outcome_Day column\n",
    "df['Outcome_Day'] = df['treatment_outcome_date'].dt.day_name()\n",
    "\n",
    "# Add Outcome_Weekend_Flag column (1 if Sat/Sun, else 0)\n",
    "df['Outcome_Weekend_Flag'] = df['Outcome_Day'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "\n",
    "# Add Report_Duration column (difference in days)\n",
    "df['Report_Duration'] = (df['treatment_outcome_date'] - df['treatment_end_date']).dt.days\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137155c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Outcome_Quarter'] = pd.to_datetime(df['treatment_outcome_date']).dt.quarter\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbc475",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split provider_name into first and last name\n",
    "df[['provider_first_name', 'provider_last_name']] = df['provider_name'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# Split patient_name into first and last name\n",
    "df[['patient_first_name', 'patient_last_name']] = df['patient_name'].str.split(' ', n=1, expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07675fc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established successfully.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create a new SQLite database (or connect if it already exists)\n",
    "    conn = sqlite3.connect('healthcare_data.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # You can add any table creation or setup code here if needed\n",
    "    print(\"Database connection established successfully.\")\n",
    "\n",
    "    # Commit any changes (optional here if nothing to commit)\n",
    "    conn.commit()\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(\"An error occurred while connecting to the database:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b38cc7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Reconnect to the database\n",
    "    conn = sqlite3.connect('healthcare_data.db')\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected to the database.\")\n",
    "\n",
    "    # 1. TREATMENT table (Fact Table)\n",
    "    cursor.execute('DROP TABLE IF EXISTS TREATMENT;')\n",
    "\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE TREATMENT (\n",
    "        Treatment_ID INTEGER PRIMARY KEY,\n",
    "        Start_Date TEXT,\n",
    "        Completion_Date TEXT,\n",
    "        Outcome_Date TEXT,\n",
    "        Outcome_Quarter INTEGER,\n",
    "        Treatment_Duration INTEGER,\n",
    "        Cost REAL,\n",
    "        Effectiveness_Score INTEGER,\n",
    "        Type TEXT,\n",
    "        Patient_ID INTEGER,\n",
    "        Provider_ID INTEGER,\n",
    "        Location_ID INTEGER,\n",
    "        Disease_ID INTEGER,\n",
    "        Outcome_Day TEXT,\n",
    "        Outcome_Weekend_Flag INTEGER,\n",
    "        Report_Duration INTEGER,\n",
    "        FOREIGN KEY (Patient_ID) REFERENCES PATIENT(Patient_ID),\n",
    "        FOREIGN KEY (Provider_ID) REFERENCES PROVIDER(Provider_ID),\n",
    "        FOREIGN KEY (Location_ID) REFERENCES LOCATION(Location_ID),\n",
    "        FOREIGN KEY (Disease_ID) REFERENCES DISEASE(Disease_ID)\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    # 2. PATIENT table (Dimension Table)\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS PATIENT (\n",
    "        Patient_ID INTEGER PRIMARY KEY,\n",
    "        First_Name TEXT,\n",
    "        Last_Name TEXT,\n",
    "        Name TEXT,\n",
    "        Gender TEXT,\n",
    "        Age INTEGER\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    # 3. PROVIDER table (Dimension Table)\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS PROVIDER (\n",
    "        Provider_ID INTEGER PRIMARY KEY,\n",
    "        First_Name TEXT,\n",
    "        Last_Name TEXT,\n",
    "        Speciality_Id INTEGER,\n",
    "        Speciality_Name TEXT,\n",
    "        Affiliated_Hospital TEXT\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    # 4. DISEASE table (Dimension Table)\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS DISEASE (\n",
    "        Disease_ID INTEGER PRIMARY KEY,\n",
    "        Speciality_Id INTEGER,\n",
    "        Name TEXT,\n",
    "        Type TEXT,\n",
    "        Severity TEXT,\n",
    "        Transmission_mode TEXT,\n",
    "        Mortality_Rate REAL\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    # 5. LOCATION table (Dimension Table)\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS LOCATION (\n",
    "        Location_ID INTEGER PRIMARY KEY,\n",
    "        Country TEXT,\n",
    "        State TEXT,\n",
    "        City TEXT\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    # 6. EFFECTIVENESS (Dimension Table)\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS EFFECTIVENESS (\n",
    "    Effectiveness_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Outcome_Status TEXT UNIQUE,\n",
    "    Effectiveness_Score INTEGER\n",
    "    );\n",
    "\n",
    "    ''')\n",
    "\n",
    "    # Commit the changes\n",
    "    conn.commit()\n",
    "    print(\"Tables created successfully.\")\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d0ffe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Connect to your database (change path as needed)\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 2: Populate DIM_EFFECTIVENESS table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS EFFECTIVENESS (\n",
    "    Effectiveness_ID INTEGER PRIMARY KEY,\n",
    "    Outcome_Status TEXT UNIQUE,\n",
    "    Effectiveness_Score INTEGER\n",
    "    );\n",
    "''')\n",
    "\n",
    "\n",
    "effectiveness_mapping = {\n",
    "    'deceased': 0,\n",
    "    'worsened': 1,\n",
    "    'unsuccessful': 2,\n",
    "    'partially successful': 3,\n",
    "    'stable': 4,\n",
    "    'successful': 5\n",
    "}\n",
    "\n",
    "for idx, (status, score) in enumerate(effectiveness_mapping.items(), start=1):\n",
    "    cursor.execute('''\n",
    "        INSERT OR IGNORE INTO EFFECTIVENESS (Effectiveness_ID, Outcome_Status, Effectiveness_Score)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (idx, status, score))\n",
    "\n",
    "\n",
    "# Save and close\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Lookup table populated and TREATMENT table updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2c7df",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = sqlite3.connect('healthcare_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Track unique location combinations to avoid duplicates\n",
    "unique_locations = set()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Insert into PATIENT using unique Patient_ID\n",
    "    cursor.execute('''\n",
    "    INSERT OR IGNORE INTO PATIENT (Patient_ID, First_Name, Last_Name, Gender, Age)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (row['patient_id'], row['patient_first_name'], row['patient_last_name'], row['gender'], row['age']))\n",
    "\n",
    "    # Insert into PROVIDER using unique Provider_ID\n",
    "    cursor.execute('''\n",
    "    INSERT OR IGNORE INTO PROVIDER (Provider_ID, First_Name, Last_Name, Speciality_Id, Speciality_Name, Affiliated_Hospital)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (row['provider_id'], row['provider_first_name'], row['provider_last_name'], row['speciality_id_x'], row['speciality_name'], row['affiliated_hospital']))\n",
    "\n",
    "    # Insert into DISEASE using unique Disease_ID\n",
    "    cursor.execute('''\n",
    "    INSERT OR IGNORE INTO DISEASE (Disease_ID, Speciality_Id, Name, Type, Severity, Transmission_Mode, Mortality_Rate)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (row['disease_id'], row['speciality_id_x'], row['disease_name'], row['disease_type'], row['severity'], row['transmission_mode'], row['mortality_rate']))\n",
    "\n",
    "    # Handle LOCATION uniqueness by (Country, State, City) combination\n",
    "    location_key = (row['country'], row['state'], row['city'])\n",
    "    if location_key not in unique_locations:\n",
    "        cursor.execute('''\n",
    "        INSERT INTO LOCATION (Location_ID, Country, State, City)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        ''', (row['location_id'], row['country'], row['state'], row['city']))\n",
    "        unique_locations.add(location_key)\n",
    "\n",
    "    effectiveness_score = effectiveness_mapping.get(row['treatment_outcome_status'].lower(), None)\n",
    "\n",
    "    # Insert into TREATMENT (fact table, always insert)\n",
    "    cursor.execute('''\n",
    "    INSERT INTO TREATMENT (\n",
    "        Treatment_ID, Start_Date, Completion_Date, Outcome_Date, Outcome_Quarter, Treatment_Duration, Cost, \n",
    "        Effectiveness_Score, Type, Patient_ID, Provider_ID, Location_ID, Disease_ID,\n",
    "        Outcome_Day, Outcome_Weekend_Flag, Report_Duration\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        row['treatment_id'],\n",
    "        row['treatment_start_date'].strftime('%Y-%m-%d') if pd.notnull(row['treatment_start_date']) else None,\n",
    "        row['treatment_end_date'].strftime('%Y-%m-%d') if pd.notnull(row['treatment_end_date']) else None,\n",
    "        row['treatment_outcome_date'].strftime('%Y-%m-%d') if pd.notnull(row['treatment_outcome_date']) else None,\n",
    "        row['Outcome_Quarter'],\n",
    "        row['treatment_duration'],\n",
    "        row['treatment_cost'],\n",
    "        #row['treatment_outcome_status'],\n",
    "        effectiveness_score,\n",
    "        row['treatment_type'],\n",
    "        row['patient_id'],\n",
    "        row['provider_id'],\n",
    "        row['location_id'],\n",
    "        row['disease_id'],\n",
    "        row['Outcome_Day'],\n",
    "        row['Outcome_Weekend_Flag'],\n",
    "        row['Report_Duration']\n",
    "    ))\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed169ab3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect('healthcare_data.db')\n",
    "\n",
    "# Run your query and load into DataFrame\n",
    "query = 'SELECT * FROM TREATMENT LIMIT 5;'\n",
    "df_result = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Print in nice table format\n",
    "print(tabulate(df_result, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ca61ac",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database healthcare_data.db deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify the database file path\n",
    "db_file = 'healthcare_data.db'\n",
    "\n",
    "# Check if the database file exists\n",
    "if os.path.exists(db_file):\n",
    "    os.remove(db_file)\n",
    "    print(f\"Database {db_file} deleted successfully.\")\n",
    "else:\n",
    "    print(f\"Database {db_file} does not exist.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.538943,
   "end_time": "2025-04-25T00:01:04.399140",
   "environment_variables": {},
   "exception": true,
   "input_path": "/Users/avinashmacbookair/Documents/TREND Health Partners/notebooks/Healthcare_ETL_Project1.ipynb",
   "output_path": "/Users/avinashmacbookair/Documents/TREND Health Partners/notebooks/Healthcare_ETL_Project1.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T00:01:00.860197",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
